import logging
import time
import numpy as np
import torch
import base64
import traceback
import sys
import os

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
if project_root not in sys.path:
    sys.path.append(project_root)
from config.model_config import get_model_cache_dir

# è·å–CosyVoiceè·¯å¾„
COSYVOICE_PATH = os.path.join(os.path.dirname(__file__), 'CosyVoice')
sys.path.insert(0, "D:/upmicProject/BU2-Sys/AIAssistant/TTS/CosyVoice/third_party/Matcha-TTS")
def setup_cosyvoice():
    """æ‰‹åŠ¨è®¾ç½®CosyVoiceç¯å¢ƒ"""
    print(f"ğŸ” å½“å‰å·¥ä½œç›®å½•: {os.getcwd()}")
    print(f"ğŸ” å½“å‰æ–‡ä»¶è·¯å¾„: {__file__}")
    print(f"ğŸ” CosyVoiceè·¯å¾„: {COSYVOICE_PATH}")
    print(f"ğŸ” è·¯å¾„æ˜¯å¦å­˜åœ¨: {os.path.exists(COSYVOICE_PATH)}")
    
    # å¼ºåˆ¶é‡æ–°è®¾ç½®è·¯å¾„ï¼ˆç¡®ä¿ä¼˜å…ˆçº§ï¼‰
    if COSYVOICE_PATH in sys.path:
        sys.path.remove(COSYVOICE_PATH)
    sys.path.insert(0, COSYVOICE_PATH)
    print(f"ğŸ” å·²é‡æ–°æ·»åŠ åˆ°sys.path: {COSYVOICE_PATH}")
    
    # åŒæ—¶æ·»åŠ ä¸€äº›å¯èƒ½éœ€è¦çš„é¢å¤–è·¯å¾„
    extra_paths = [
        os.path.join(COSYVOICE_PATH, 'third_party', 'Matcha-TTS'),
        os.path.dirname(__file__)  # TTSç›®å½•
    ]
    
    for extra_path in extra_paths:
        if os.path.exists(extra_path) and extra_path not in sys.path:
            sys.path.insert(0, extra_path)
            print(f"ğŸ” å·²æ·»åŠ é¢å¤–è·¯å¾„: {extra_path}")
    
    # æ£€æŸ¥å¿…è¦çš„æ–‡ä»¶
    required_files = [
        'cosyvoice',
        'pretrained_models'  # å¦‚æœæœ‰çš„è¯
    ]
    
    for file in required_files:
        full_path = os.path.join(COSYVOICE_PATH, file)
        if os.path.exists(full_path):
            print(f"âœ… æ‰¾åˆ°: {file}")
        else:
            print(f"âŒ ç¼ºå¤±: {file}")
    
    # æ£€æŸ¥cosyvoiceæ¨¡å—çš„å…·ä½“è·¯å¾„
    cosyvoice_module_path = os.path.join(COSYVOICE_PATH, 'cosyvoice')
    cosyvoice_cli_path = os.path.join(cosyvoice_module_path, 'cli')
    cosyvoice_py_path = os.path.join(cosyvoice_cli_path, 'cosyvoice.py')
    print(f"ğŸ” cosyvoiceæ¨¡å—è·¯å¾„: {cosyvoice_module_path}")
    print(f"ğŸ” cosyvoice.cliè·¯å¾„: {cosyvoice_cli_path}")
    print(f"ğŸ” cosyvoice.pyæ–‡ä»¶: {cosyvoice_py_path}")
    print(f"ğŸ” cosyvoice.pyå­˜åœ¨: {os.path.exists(cosyvoice_py_path)}")
    
    return True

setup_cosyvoice()

# æ¨è¿Ÿå¯¼å…¥CosyVoice2ï¼Œé¿å…åˆå§‹åŒ–æ—¶çš„å¯¼å…¥é”™è¯¯
CosyVoice2 = None
load_wav = None

def _import_cosyvoice():
    """å»¶è¿Ÿå¯¼å…¥CosyVoice2æ¨¡å—"""
    global CosyVoice2, load_wav
    if CosyVoice2 is None:
        # ç¡®ä¿è·¯å¾„è®¾ç½®æ­£ç¡®
        setup_cosyvoice()
        
        try:
            from cosyvoice.cli.cosyvoice import CosyVoice2 as _CosyVoice2
            from cosyvoice.utils.file_utils import load_wav as _load_wav
            CosyVoice2 = _CosyVoice2
            load_wav = _load_wav
            print("âœ… æˆåŠŸå¯¼å…¥ CosyVoice2 æ¨¡å—")
        except ImportError as e:
            print(f"âŒ å¯¼å…¥å¤±è´¥: {e}")
            print("å°è¯•å¼ºåˆ¶é‡ç½®Pythonè·¯å¾„ç¼“å­˜...")
            
            # æ¸…é™¤æ¨¡å—ç¼“å­˜
            import importlib
            if 'cosyvoice' in sys.modules:
                del sys.modules['cosyvoice']
            if 'cosyvoice.cli' in sys.modules:
                del sys.modules['cosyvoice.cli']
            if 'cosyvoice.cli.cosyvoice' in sys.modules:
                del sys.modules['cosyvoice.cli.cosyvoice']
            
            # é‡æ–°å¼ºåˆ¶è®¾ç½®è·¯å¾„
            extra_path = os.path.join(os.path.dirname(__file__), 'CosyVoice')
            if extra_path in sys.path:
                sys.path.remove(extra_path)
            sys.path.insert(0, extra_path)
            
            try:
                from cosyvoice.cli.cosyvoice import CosyVoice2 as _CosyVoice2
                from cosyvoice.utils.file_utils import load_wav as _load_wav
                CosyVoice2 = _CosyVoice2
                load_wav = _load_wav
                print("âœ… æ¸…é™¤ç¼“å­˜åæˆåŠŸå¯¼å…¥")
            except ImportError as e2:
                print(f"âŒ ä»ç„¶å¯¼å…¥å¤±è´¥: {e2}")
                print(f"å½“å‰sys.path: {sys.path[:5]}...")  # åªæ˜¾ç¤ºå‰5ä¸ªè·¯å¾„
                raise
    return CosyVoice2, load_wav

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('assistant.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

# éŸ³é¢‘ç¼“å†²é…ç½® - ä¼˜åŒ–è·¨å¹³å°å…¼å®¹æ€§å’ŒéŸ³è´¨
BUFFER_SIZE = 24576  # 24KBç¼“å†²åŒºï¼Œæé«˜éŸ³è´¨ç¨³å®šæ€§
MIN_CHUNK_SIZE = 6144   # 6KBæœ€å°å—ï¼Œä¿è¯éŸ³é¢‘è¿ç»­æ€§
MAX_BUFFER_TIME = 0.08  # 80msæœ€å¤§ç¼“å†²æ—¶é—´ï¼Œå¹³è¡¡å»¶è¿Ÿå’Œç¨³å®šæ€§

# æµå¼æ’­æ”¾ä¼˜åŒ–é…ç½® - é’ˆå¯¹ç½‘ç»œä¼ è¾“ä¼˜åŒ–
STREAM_BUFFER_SIZE = 32768   # 32KBæµå¼ç¼“å†²åŒºï¼Œå‡å°‘ç½‘ç»œæŠ–åŠ¨å½±å“
STREAM_MIN_CHUNK_SIZE = 12288 # 12KBæœ€å°æµå¼å—ï¼Œç¡®ä¿éŸ³é¢‘è´¨é‡
STREAM_PREFETCH_TIME = 0.15   # 150msé¢„å–æ—¶é—´ï¼Œä¼˜åŒ–æ’­æ”¾æµç•…åº¦

# é‡‡æ ·ç‡é…ç½® - ç¡®ä¿è·¨å¹³å°ä¸€è‡´æ€§
OUTPUT_SAMPLE_RATE = 24000    # CosyVoice2æ ‡å‡†è¾“å‡ºé‡‡æ ·ç‡
INPUT_SAMPLE_RATE = 16000     # è¾“å…¥éŸ³é¢‘æ ‡å‡†é‡‡æ ·ç‡
AUDIO_CHANNELS = 1            # å•å£°é“è¾“å‡º
AUDIO_BITS_PER_SAMPLE = 16    # 16ä½PCM

# åˆå§‹åŒ–CosyVoiceæ¨¡å‹
model_path = os.path.join(get_model_cache_dir("modelscope"), "iic\\CosyVoice2-0___5B")

# ä¼˜åŒ–æ¨¡å‹åŠ è½½å’Œé…ç½®
def optimize_cosyvoice_model():
    # å¯¼å…¥CosyVoice2æ¨¡å—
    CosyVoice2_class, _ = _import_cosyvoice()
    
    # å¯ç”¨ä¼˜åŒ–è®¾ç½®
    torch.backends.cudnn.benchmark = True
    torch.backends.cudnn.deterministic = False
    
    # åŠ è½½æ¨¡å‹æ—¶çš„ä¼˜åŒ–
    cosyvoice = CosyVoice2_class(
        model_path,
        load_jit=True,  # ç¦ç”¨JITç¼–è¯‘ä»¥é¿å…å…¼å®¹æ€§é—®é¢˜
        load_trt=True,  # ç¦ç”¨TensorRTä»¥é¿å…ç‰ˆæœ¬ä¸å…¼å®¹é—®é¢˜
        fp16=True       # ç¦ç”¨fp16ä»¥ç¡®ä¿å…¼å®¹æ€§
    )
    return cosyvoice


class AudioBuffer:
    """éŸ³é¢‘ç¼“å†²ç±»ï¼Œç”¨äºä¼˜åŒ–æµå¼ä¼ è¾“"""
    def __init__(self, buffer_size=BUFFER_SIZE, min_chunk_size=MIN_CHUNK_SIZE, stream_mode=False):
        # æ ¹æ®æ˜¯å¦ä¸ºæµå¼æ¨¡å¼é€‰æ‹©ä¸åŒçš„ç¼“å†²åŒºé…ç½®
        if stream_mode:
            self.buffer_size = STREAM_BUFFER_SIZE
            self.min_chunk_size = STREAM_MIN_CHUNK_SIZE
            self.max_buffer_time = MAX_BUFFER_TIME
        else:
            self.buffer_size = buffer_size
            self.min_chunk_size = min_chunk_size
            self.max_buffer_time = MAX_BUFFER_TIME
            
        self.buffer = bytearray()
        self.last_yield_time = time.time()
        self.stream_mode = stream_mode
        self.chunk_count = 0
        
    def add_data(self, data):
        """æ·»åŠ æ•°æ®åˆ°ç¼“å†²åŒº"""
        self.buffer.extend(data)
        
    def should_yield(self):
        """åˆ¤æ–­æ˜¯å¦åº”è¯¥è¾“å‡ºæ•°æ®"""
        current_time = time.time()
        time_since_last_yield = current_time - self.last_yield_time
        
        if self.stream_mode:
            # æµå¼æ¨¡å¼ï¼šæ›´æ™ºèƒ½çš„è¾“å‡ºç­–ç•¥
            # 1. è¾¾åˆ°æœ€å°å—å¤§å°å°±å¯ä»¥è¾“å‡ºï¼ˆä¿è¯ä½å»¶è¿Ÿï¼‰
            # 2. æˆ–è€…è¾¾åˆ°ç¼“å†²åŒºå¤§å°ï¼ˆä¿è¯æ•ˆç‡ï¼‰
            # 3. æˆ–è€…ç­‰å¾…æ—¶é—´è¿‡é•¿ï¼ˆé¿å…å¡é¡¿ï¼‰
            return (len(self.buffer) >= self.min_chunk_size or 
                    len(self.buffer) >= self.buffer_size or
                    (len(self.buffer) > 0 and time_since_last_yield > self.max_buffer_time))
        else:
            # æ™®é€šæ¨¡å¼ï¼šåŸæœ‰é€»è¾‘
            return (len(self.buffer) >= self.buffer_size or 
                    (len(self.buffer) >= self.min_chunk_size and time_since_last_yield > self.max_buffer_time))
    
    def get_data(self):
        """è·å–ç¼“å†²åŒºæ•°æ®å¹¶æ¸…ç©º"""
        if len(self.buffer) > 0:
            data = bytes(self.buffer)
            self.buffer.clear()
            self.last_yield_time = time.time()
            self.chunk_count += 1
            return data
        return None
    
    def flush(self):
        """å¼ºåˆ¶è¾“å‡ºå‰©ä½™æ•°æ®"""
        return self.get_data()
    
    def get_stats(self):
        """è·å–ç¼“å†²åŒºç»Ÿè®¡ä¿¡æ¯"""
        return {
            'buffer_size': len(self.buffer),
            'chunk_count': self.chunk_count,
            'stream_mode': self.stream_mode
        }


class CosyVoiceTTS:
    def __init__(self,tts_volume=1.0,tts_speed=1.0,video_path="input.wav"):
        self.recorded_audio = None  # å­˜å‚¨å½•åˆ¶çš„éŸ³é¢‘
        self.default_audio = None   # å­˜å‚¨é»˜è®¤éŸ³é¢‘
        self.prompt_speech_16k = None
        self.cosyvoice = optimize_cosyvoice_model()
        self.load_default_audio(video_path if video_path is not None else "input.wav")
        self._is_registered = False  # æ·»åŠ æ ‡å¿—ä½
        self.stop_inference = False  # æ·»åŠ æ¨ç†åœæ­¢æ ‡å¿—
        pass

    def load_default_audio(self,file_path="input.wav"):
        """åŠ è½½é»˜è®¤éŸ³é¢‘"""
        try:
            self.default_audio = load_default_audio(file_path)
            self.prompt_speech_16k = self.default_audio
            logger.info("é»˜è®¤éŸ³é¢‘åŠ è½½å®Œæˆ")
        except Exception as e:
            logger.error(f"åŠ è½½é»˜è®¤éŸ³é¢‘å¤±è´¥: {str(e)}")
            self.default_audio = prepare_audio_data(None, target_length=16000)
    
    def get_prompt_audio(self):
        """è·å–ç”¨äºTTSçš„promptéŸ³é¢‘ï¼ˆä¼˜å…ˆä½¿ç”¨å½•åˆ¶éŸ³é¢‘ï¼Œå¦åˆ™ä½¿ç”¨é»˜è®¤éŸ³é¢‘ï¼‰"""
        if self.recorded_audio is not None:
            logger.info("ä½¿ç”¨å½•åˆ¶çš„éŸ³é¢‘ä½œä¸ºprompt")
            return self.recorded_audio
        else:
            logger.info("ä½¿ç”¨é»˜è®¤éŸ³é¢‘ä½œä¸ºprompt")
            return self.default_audio

    def request_stop_inference(self):
        """è¯·æ±‚åœæ­¢æ¨ç†è¿‡ç¨‹"""
        logger.info("æ”¶åˆ°åœæ­¢æ¨ç†è¯·æ±‚")
        self.stop_inference = True

    def reset_stop_flag(self):
        """é‡ç½®åœæ­¢æ ‡å¿—"""
        self.stop_inference = False

    def apply_volume_adjustment(self,speech_data, volume):
        """åº”ç”¨éŸ³é‡è°ƒæ•´"""
        # ç¡®ä¿éŸ³é‡åœ¨åˆç†èŒƒå›´å†…
        volume = max(0.1, min(7.0, volume))
        
        # è®¡ç®—è°ƒæ•´åçš„ä¹˜æ•°ï¼Œé¿å…éŸ³é¢‘å‰Šå³°
        base_multiplier = 32767
        adjusted_multiplier = base_multiplier * volume
        
        # å¦‚æœéŸ³é‡è¿‡å¤§ï¼Œéœ€è¦æ£€æŸ¥æ˜¯å¦ä¼šå¯¼è‡´å‰Šå³°
        if volume > 1.0:
            # è®¡ç®—å½“å‰éŸ³é¢‘çš„æœ€å¤§ç»å¯¹å€¼
            max_val = np.abs(speech_data).max()
            if max_val > 0:
                # ç¡®ä¿ä¸ä¼šè¶…è¿‡16-bitèŒƒå›´
                safe_multiplier = 32767 / max_val
                adjusted_multiplier = min(adjusted_multiplier, safe_multiplier)
        
        logger.info(f"éŸ³é‡è°ƒæ•´: {volume:.1f}å€, ä¹˜æ•°: {adjusted_multiplier:.0f}")
        
        return (speech_data * adjusted_multiplier).astype(np.int16)

    def generate_audio_stream(self, tts_text,instruct_text="è¯·ç”¨è‡ªç„¶æµç•…çš„è¯­è°ƒæœ—è¯»", volume=1.0, speed=1.0, buffer_size=BUFFER_SIZE,cloneprompt_speech_16k=None):
        """ä½¿ç”¨æµå¼ç¼“å†²ä¼˜åŒ–çš„éŸ³é¢‘ç”Ÿæˆ"""
        # é‡ç½®åœæ­¢æ ‡å¿—
        self.stop_inference = False
        
        # TTSå‚æ•°è®¾ç½®
        stream = True
        # åˆå§‹åŒ–éŸ³é¢‘ç¼“å†²åŒºï¼ˆå¯ç”¨æµå¼æ¨¡å¼ï¼‰
        is_stream_mode = stream
        buffer = AudioBuffer(buffer_size=buffer_size, stream_mode=is_stream_mode)
        
        logger.info(f"åˆå§‹åŒ–éŸ³é¢‘ç¼“å†²åŒº: æµå¼æ¨¡å¼={is_stream_mode}, ç¼“å†²åŒºå¤§å°={buffer.buffer_size}, æœ€å°å—={buffer.min_chunk_size}")
        
        logger.info(f"å¼€å§‹CosyVoiceæ¨ç†: text={tts_text[:50]}...")
        logger.info(f"ä½¿ç”¨promptéŸ³é¢‘: å½¢çŠ¶={self.prompt_speech_16k.shape}")
        cloneprompt_speech_16k = cloneprompt_speech_16k if cloneprompt_speech_16k is not None else self.prompt_speech_16k
        try:
            print("instruct_text:",instruct_text)
            print("tts_text:",tts_text)
            # ä½¿ç”¨instruct2æ–¹æ³•è¿›è¡Œæ¨ç†
            for model_output in self.cosyvoice.inference_instruct2(
                tts_text, 
                instruct_text, 
                cloneprompt_speech_16k, 
                stream=stream
            ):
                # æ£€æŸ¥æ˜¯å¦è¯·æ±‚åœæ­¢æ¨ç†
                if self.stop_inference:
                    logger.info("æ¨ç†è¿‡ç¨‹è¢«ä¸­æ–­ï¼Œåœæ­¢ç”ŸæˆéŸ³é¢‘")
                    return  # ç›´æ¥è¿”å›ï¼Œä¸å†å¤„ç†åç»­è¾“å‡º
                
                try:
                    # è·å–éŸ³é¢‘æ•°æ®å¹¶è¿›è¡ŒéŸ³é‡è°ƒæ•´
                    speech_data = model_output['tts_speech'].cpu().numpy()
                    speech_data = self.apply_volume_adjustment(speech_data, volume)
                    
                    # æ·»åŠ åˆ°ç¼“å†²åŒº
                    buffer.add_data(speech_data.tobytes())
                    
                    # æ£€æŸ¥æ˜¯å¦éœ€è¦è¾“å‡º
                    if buffer.should_yield():
                        # å†æ¬¡æ£€æŸ¥åœæ­¢æ ‡å¿—ï¼ˆåœ¨è¾“å‡ºå‰ï¼‰
                        if self.stop_inference:
                            logger.info("æ¨ç†è¿‡ç¨‹è¢«ä¸­æ–­ï¼Œåœæ­¢ç”ŸæˆéŸ³é¢‘")
                            return
                        
                        data = buffer.get_data()
                        if data:
                            # å°†éŸ³é¢‘æ•°æ®ç¼–ç ä¸ºbase64
                            audio_base64 = base64.b64encode(data).decode('utf-8')
                            
                            # æ„é€ éŸ³é¢‘æ•°æ®åŒ…
                            audio_data = {
                                'data': audio_base64, 
                                'chunk_id': buffer.chunk_count,
                                'size': len(data),
                                'sample_rate': OUTPUT_SAMPLE_RATE,  # ä½¿ç”¨ç»Ÿä¸€çš„é‡‡æ ·ç‡é…ç½®
                                'channels': AUDIO_CHANNELS,
                                'data_type': 'int16',  # éŸ³é‡è°ƒæ•´åçš„æ•°æ®ç±»å‹
                                'volume': volume,
                                'speed': speed
                            }
                            yield audio_data
                            
                except Exception as e:
                    logger.error(f"å¤„ç†éŸ³é¢‘æ•°æ®æ—¶å‡ºé”™: {str(e)}")
                    continue
            
            # è¾“å‡ºå‰©ä½™çš„ç¼“å†²æ•°æ®ï¼ˆä»…åœ¨æœªè¢«ä¸­æ–­æ—¶ï¼‰
            if not self.stop_inference:
                remaining_data = buffer.flush()
                if remaining_data:
                    audio_base64 = base64.b64encode(remaining_data).decode('utf-8')
                    audio_data = {
                        'data': audio_base64,
                        'chunk_id': buffer.chunk_count,
                        'size': len(remaining_data),
                        'sample_rate': OUTPUT_SAMPLE_RATE,
                        'channels': AUDIO_CHANNELS,
                        'data_type': 'int16',
                        'volume': volume,
                        'speed': speed,
                        'final_chunk': True  # æ ‡è®°æœ€åä¸€ä¸ªå—
                    }
                    yield audio_data
                # è¾“å‡ºç¼“å†²åŒºç»Ÿè®¡ä¿¡æ¯
                stats = buffer.get_stats()
                logger.info(f"éŸ³é¢‘ç”Ÿæˆå®Œæˆï¼Œç¼“å†²åŒºç»Ÿè®¡: {stats}")
            else:
                logger.info("æ¨ç†è¢«ä¸­æ–­ï¼Œè·³è¿‡å‰©ä½™æ•°æ®è¾“å‡º")
        except Exception as e:
            logger.error(f"CosyVoiceæ¨ç†è¿‡ç¨‹ä¸­å‡ºé”™: {str(e)}")
            logger.error(traceback.format_exc())
            raise


    def generate_audio(self, text,instruct_text="è¯·ç”¨è‡ªç„¶æµç•…çš„è¯­è°ƒæœ—è¯»", speed=1.0,stream=False):
        voice_response = self.cosyvoice.inference_instruct2(
            text,
            instruct_text,
            self.prompt_speech_16k,
            stream=stream,
            speed=speed
        )
        # for i,j in enumerate(voice_response):
        #     torchaudio.save('instruct_{}.wav'.format(i), j['tts_speech'], self.cosyvoice.sample_rate)
        return voice_response

    def set_recorded_audio(self, audio_data):
        self.recorded_audio = audio_data
        """åŠ è½½é»˜è®¤éŸ³é¢‘"""
        try:
            self.default_audio = load_default_audio("input.wav")
            logger.info("é»˜è®¤éŸ³é¢‘åŠ è½½å®Œæˆ")
        except Exception as e:
            logger.error(f"åŠ è½½é»˜è®¤éŸ³é¢‘å¤±è´¥: {str(e)}")
            self.default_audio = prepare_audio_data(None, target_length=16000)
        pass

    def register_audio_data(self):
        if self._is_registered:
            return
        for i in range(3):
            voice_response = self.generate_audio_stream("å¼€å§‹é¢„çƒ­æ¨¡å‹")
            for audio_data in voice_response:
                pass
        self._is_registered = True
        print("======================åˆå§‹åŒ–æˆåŠŸ================")

def load_default_audio(file_path="input.wav", target_length=16000):
    """åŠ è½½é»˜è®¤éŸ³é¢‘æ–‡ä»¶"""
    try:
        if not os.path.exists(file_path):
            logger.warning(f"é»˜è®¤éŸ³é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
            return prepare_audio_data(None, target_length)
        
        logger.info(f"åŠ è½½é»˜è®¤éŸ³é¢‘æ–‡ä»¶: {file_path}")
        # ä½¿ç”¨CosyVoiceçš„load_wavå‡½æ•°åŠ è½½éŸ³é¢‘
        _, load_wav_func = _import_cosyvoice()
        speech_16k = load_wav_func(file_path, 16000)
        
        # ç¡®ä¿æ˜¯æ­£ç¡®çš„æ ¼å¼
        if speech_16k.dim() == 1:
            speech_16k = speech_16k.unsqueeze(0)  # è½¬ä¸º [1, samples]
        
        logger.info(f"é»˜è®¤éŸ³é¢‘åŠ è½½æˆåŠŸ: å½¢çŠ¶={speech_16k.shape}")
        return speech_16k
    except Exception as e:
        logger.error(f"åŠ è½½é»˜è®¤éŸ³é¢‘å‡ºé”™: {str(e)}")
        return prepare_audio_data(None, target_length)
    
def prepare_audio_data(audio_list, target_length=16000):
    """å‡†å¤‡éŸ³é¢‘æ•°æ®ï¼Œç¡®ä¿æ ¼å¼æ­£ç¡®"""
    logger.info(f"åŸå§‹éŸ³é¢‘æ•°æ®ç±»å‹: {type(audio_list)}")
    
    if not audio_list:
        # åˆ›å»ºé»˜è®¤é™éŸ³éŸ³é¢‘
        audio_list = [0.0] * target_length
        logger.info(f"ä½¿ç”¨é»˜è®¤é™éŸ³éŸ³é¢‘ï¼Œé•¿åº¦: {target_length}")
    
    # è½¬æ¢ä¸ºnumpyæ•°ç»„
    audio_array = np.array(audio_list, dtype=np.float32)
    logger.info(f"è½¬æ¢ä¸ºnumpyæ•°ç»„å: å½¢çŠ¶={audio_array.shape}, ç»´åº¦={audio_array.ndim}")
    
    # å¼ºåˆ¶ç¡®ä¿æ˜¯1ç»´æ•°ç»„
    if audio_array.ndim > 1:
        logger.info(f"æ£€æµ‹åˆ°å¤šç»´æ•°ç»„ï¼Œä» {audio_array.shape} å±•å¹³ä¸º1ç»´")
        audio_array = audio_array.flatten()
    
    # ç¡®ä¿è¾“å‡ºæ˜¯1ç»´çš„
    if audio_array.ndim != 1:
        raise ValueError(f"éŸ³é¢‘æ•°æ®å¿…é¡»æ˜¯1ç»´çš„ï¼Œå½“å‰ç»´åº¦: {audio_array.ndim}")
    
    logger.info(f"å±•å¹³åçš„éŸ³é¢‘æ•°ç»„: å½¢çŠ¶={audio_array.shape}, é•¿åº¦={len(audio_array)}")
    
    # è°ƒæ•´é•¿åº¦
    if len(audio_array) < target_length:
        # å¦‚æœå¤ªçŸ­ï¼Œç”¨é›¶å¡«å……
        pad_length = target_length - len(audio_array)
        audio_array = np.pad(audio_array, (0, pad_length), mode='constant', constant_values=0.0)
        logger.info(f"éŸ³é¢‘å¤ªçŸ­ï¼Œå¡«å……äº† {pad_length} ä¸ªé›¶")
    elif len(audio_array) > target_length:
        # å¦‚æœå¤ªé•¿ï¼Œæˆªæ–­åˆ°ç›®æ ‡é•¿åº¦
        audio_array = audio_array[:target_length]
        logger.info(f"éŸ³é¢‘å¤ªé•¿ï¼Œæˆªæ–­åˆ° {target_length}")
    
    # è½¬æ¢ä¸ºtorch tensorï¼Œé¦–å…ˆåˆ›å»º1ç»´å¼ é‡
    audio_tensor = torch.tensor(audio_array, dtype=torch.float32)
    
    # *** å…³é”®ä¿®å¤ï¼šè½¬æ¢ä¸ºäºŒç»´å¼ é‡ [1, samples] æ ¼å¼ ***
    # CosyVoice çš„ resample å’Œç‰¹å¾æå–å™¨æœŸæœ›äºŒç»´å¼ é‡
    audio_tensor = audio_tensor.unsqueeze(0)  # ä» [samples] å˜ä¸º [1, samples]
    
    logger.info(f"æœ€ç»ˆéŸ³é¢‘å¼ é‡: å½¢çŠ¶={audio_tensor.shape}, ç»´åº¦={audio_tensor.dim()}, ç±»å‹={audio_tensor.dtype}")
    logger.info(f"éŸ³é¢‘å¼ é‡è¯¦ç»†ä¿¡æ¯: channels={audio_tensor.shape[0]}, samples={audio_tensor.shape[1]}")
    
    # æœ€åçš„å®‰å…¨æ£€æŸ¥
    if audio_tensor.shape[0] != 1:
        logger.error(f"éŸ³é¢‘å¼ é‡é€šé“æ•°é”™è¯¯ï¼æœŸæœ›: 1, å®é™…: {audio_tensor.shape[0]}")
    if audio_tensor.shape[1] != target_length:
        logger.warning(f"éŸ³é¢‘é•¿åº¦ä¸åŒ¹é…ï¼æœŸæœ›: {target_length}, å®é™…: {audio_tensor.shape[1]}")
    
    return audio_tensor


if __name__ == "__main__":
    cosyvoice = CosyVoiceTTS()
    audio_data = cosyvoice.generate_audio_stream("ä½ å¥½ï¼Œæˆ‘æ˜¯å°çˆ±åŒå­¦ï¼Œå¾ˆé«˜å…´è®¤è¯†ä½ ")
    print(audio_data)